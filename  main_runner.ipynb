{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ee99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- main_runner.py ---\n",
    "# Main orchestration script for running the ML asset pricing pipeline.\n",
    "# Imports config and utils, defines model training logic, runs the pipeline loops.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import re\n",
    "\n",
    "# --- Import Configuration & Utilities ---\n",
    "import config\n",
    "import pipeline_utils as utils\n",
    "\n",
    "# --- Import Model Specific Libraries ---\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV, ElasticNet, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    STATSMODELS_AVAILABLE = True\n",
    "except ImportError: STATSMODELS_AVAILABLE = False; print(\"ADVARSEL: Statsmodels ikke funnet.\")\n",
    "try:\n",
    "    # Ensure TF is imported correctly\n",
    "    import tensorflow as tf\n",
    "    tf.config.set_visible_devices([], 'GPU') # Explicitly disable GPU if causing issues, or manage memory growth\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers, regularizers, callbacks, backend as K\n",
    "    from tensorflow.keras.optimizers import Adam # Use legacy Adam if needed: from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    # Set TF seeds and deterministic options\n",
    "    os.environ['PYTHONHASHSEED']=str(config.TF_SEED)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1' # Newer TF versions might use this\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC']='1' # Note: May impact performance\n",
    "    random.seed(config.TF_SEED)\n",
    "    np.random.seed(config.TF_SEED)\n",
    "    tf.random.set_seed(config.TF_SEED)\n",
    "    # Optional: Configure GPU memory growth if using GPU\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently no GPUs are available. Uncomment if you have GPUs.\n",
    "            # tf.config.set_visible_devices(gpus[0], 'GPU') # Select specific GPU if needed\n",
    "            # for gpu in gpus:\n",
    "            #     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"GPUs funnet ({len(gpus)}), konfigurasjon forsøkt (men muligens deaktivert ovenfor).\")\n",
    "        except RuntimeError as e: print(f\"Kunne ikke sette minnevekst for GPU: {e}\")\n",
    "    else:\n",
    "        print(\"Ingen GPU funnet, bruker CPU.\")\n",
    "\n",
    "except ImportError: TENSORFLOW_AVAILABLE = False; print(\"ADVARSEL: TensorFlow/Keras ikke funnet.\")\n",
    "\n",
    "# ==========================================================================\n",
    "# --- MODEL TRAINING/EVALUATION FUNCTIONS (Per Window) ---\n",
    "# (Keep OLS, OLS3H, PLS, PCR, ENET, GLM_H, RF, GBRT_H exactly as before)\n",
    "# Define OLS\n",
    "def train_evaluate_ols(X_train_val, y_train_val, X_test, model_params):\n",
    "    try:\n",
    "        model = LinearRegression(fit_intercept=True).fit(X_train_val, y_train_val)\n",
    "        preds_oos = model.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
    "        preds_is = model.predict(X_train_val)\n",
    "        return model, preds_oos, preds_is, {}\n",
    "    except Exception as e: print(f\"    FEIL OLS: {e}\"); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "# Define OLS3H\n",
    "def train_evaluate_ols3h(X_train_val, y_train_val, X_test, model_params):\n",
    "    if not STATSMODELS_AVAILABLE: return None, np.array([]), np.array([]), {}\n",
    "    try:\n",
    "        X_tv_const = sm.add_constant(X_train_val, prepend=True, has_constant='add') # Ensure constant is added correctly\n",
    "        X_test_const = sm.add_constant(X_test, prepend=True, has_constant='add') if X_test.shape[0] > 0 else None\n",
    "        rlm_model = sm.RLM(y_train_val, X_tv_const, M=sm.robust.norms.HuberT())\n",
    "        valid_fit_params = {k: v for k, v in model_params.items() if k in ['maxiter', 'tol']}\n",
    "        fitted_model = rlm_model.fit(**valid_fit_params)\n",
    "        preds_oos = fitted_model.predict(X_test_const) if X_test_const is not None else np.array([])\n",
    "        preds_is = fitted_model.predict(X_tv_const)\n",
    "        # Store actual params used, including Huber M\n",
    "        optim_params = {'M': 'HuberT', **valid_fit_params}\n",
    "        return fitted_model, preds_oos, preds_is, optim_params\n",
    "    except Exception as e: print(f\"    FEIL OLS3H: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "\n",
    "# Define _tune_simple_model helper\n",
    "def _tune_simple_model(ModelClass, X_train, y_train, X_val, y_val, param_grid_dict):\n",
    "    best_mse = np.inf; best_param_value = None; param_name = list(param_grid_dict.keys())[0]\n",
    "    param_values = param_grid_dict[param_name]\n",
    "    # Adjust max components check for safety\n",
    "    max_components = min(X_train.shape[0], X_train.shape[1])\n",
    "    valid_grid = [p for p in param_values if isinstance(p, int) and 0 < p <= max_components]\n",
    "    if not valid_grid:\n",
    "        print(f\"    Advarsel: Ingen gyldig grid for {param_name} (max={max_components}). Bruker 1 komponent.\")\n",
    "        valid_grid = [1] # Fallback to 1 component if grid is invalid\n",
    "\n",
    "    for p_val in valid_grid:\n",
    "        try:\n",
    "            if ModelClass == Pipeline: # For PCR\n",
    "                 model_val = Pipeline([('pca', PCA(n_components=p_val)), ('lr', LinearRegression())])\n",
    "            else: # For PLS\n",
    "                 model_val = ModelClass(**{param_name: p_val, 'scale': False})\n",
    "\n",
    "            model_val.fit(X_train, y_train)\n",
    "            y_pred_val = model_val.predict(X_val).flatten()\n",
    "            if not np.all(np.isfinite(y_pred_val)): continue # Skip if predictions are not finite\n",
    "\n",
    "            mse = mean_squared_error(y_val, y_pred_val)\n",
    "            if not np.isnan(mse) and mse < best_mse:\n",
    "                 best_mse = mse; best_param_value = p_val\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"    FEIL tuning {ModelClass.__name__} {param_name}={p_val}: {e}\") # Optional debug\n",
    "            continue # Skip parameter if fitting fails\n",
    "\n",
    "    if best_param_value is None: print(f\"    FEIL: Tuning mislyktes for {ModelClass.__name__}.\")\n",
    "    return best_param_value\n",
    "\n",
    "\n",
    "# Define PLS\n",
    "def train_evaluate_pls(X_train, y_train, X_val, y_val, X_test, model_params):\n",
    "    optimal_params = {}\n",
    "    try:\n",
    "        best_n = _tune_simple_model(PLSRegression, X_train, y_train, X_val, y_val, {'n_components': model_params['n_components_grid']})\n",
    "        if best_n is None: raise ValueError(\"PLS tuning failed.\")\n",
    "        optimal_params = {'n_components': best_n}\n",
    "        X_train_val = np.vstack((X_train, X_val)); y_train_val = np.concatenate((y_train, y_val))\n",
    "        final_model = PLSRegression(n_components=best_n, scale=False).fit(X_train_val, y_train_val)\n",
    "        preds_oos = final_model.predict(X_test).flatten() if X_test.shape[0] > 0 else np.array([])\n",
    "        preds_is = final_model.predict(X_train_val).flatten()\n",
    "        return final_model, preds_oos, preds_is, optimal_params\n",
    "    except Exception as e: print(f\"    FEIL PLS: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "# Define PCR\n",
    "def train_evaluate_pcr(X_train, y_train, X_val, y_val, X_test, model_params):\n",
    "    optimal_params = {}\n",
    "    try:\n",
    "        best_n = _tune_simple_model(Pipeline, X_train, y_train, X_val, y_val, {'n_components': model_params['n_components_grid']})\n",
    "        if best_n is None: raise ValueError(\"PCR tuning failed.\")\n",
    "        optimal_params = {'n_components': best_n}\n",
    "        final_model = Pipeline([('pca', PCA(n_components=best_n)), ('lr', LinearRegression())])\n",
    "        X_train_val = np.vstack((X_train, X_val)); y_train_val = np.concatenate((y_train, y_val))\n",
    "        final_model.fit(X_train_val, y_train_val)\n",
    "        preds_oos = final_model.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
    "        preds_is = final_model.predict(X_train_val)\n",
    "        return final_model, preds_oos, preds_is, optimal_params\n",
    "    except Exception as e: print(f\"    FEIL PCR: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "# Define ENET\n",
    "def train_evaluate_enet(X_train, y_train, X_test, model_params):\n",
    "    optimal_params = {}\n",
    "    try:\n",
    "        cv_strategy = KFold(n_splits=model_params['cv_folds'], shuffle=True, random_state=config.GENERAL_SEED)\n",
    "        # Use ElasticNetCV on the combined train+val set if tuning is desired across both\n",
    "        # If tuning ONLY on train set (as paper might imply for simpler models?), fit only on X_train\n",
    "        # Let's stick to fitting CV on X_train as per the original code structure for ENET\n",
    "        enet_cv = ElasticNetCV(\n",
    "            alphas=model_params['alphas'],\n",
    "            l1_ratio=model_params['l1_ratio'],\n",
    "            fit_intercept=True,\n",
    "            cv=cv_strategy,\n",
    "            n_jobs=model_params.get('n_jobs', -1),\n",
    "            max_iter=model_params.get('max_iter', 1000),\n",
    "            tol=model_params.get('tol', 0.001),\n",
    "            random_state=config.GENERAL_SEED\n",
    "        )\n",
    "        enet_cv.fit(X_train, y_train) # Fit CV on training data only\n",
    "        optimal_params = {'alpha': enet_cv.alpha_, 'l1_ratio': enet_cv.l1_ratio_}\n",
    "\n",
    "        # Final model is the one found by CV\n",
    "        final_model = enet_cv\n",
    "        preds_oos = final_model.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
    "        preds_is = final_model.predict(X_train) # IS predictions on the data used for CV fitting\n",
    "        return final_model, preds_oos, preds_is, optimal_params\n",
    "    except Exception as e: print(f\"    FEIL ENET: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "# Define GLM_H\n",
    "def train_evaluate_glm_h(X_train, y_train, X_val, y_val, X_test, model_params):\n",
    "    optimal_params = {}; best_mse = np.inf; optim_found_params = None\n",
    "    grid = list(ParameterGrid(model_params['param_grid'])); max_iter = model_params.get('max_iter', 300)\n",
    "    # Base parameters for HuberRegressor\n",
    "    base_hub_params = {'fit_intercept': True, 'max_iter': max_iter, 'tol': 1e-6} # Add tol\n",
    "\n",
    "    for params in grid:\n",
    "        try:\n",
    "            # Combine base params with grid params\n",
    "            current_params = {**base_hub_params, **params}\n",
    "            model_val = HuberRegressor(**current_params).fit(X_train, y_train)\n",
    "            y_pred_val = model_val.predict(X_val)\n",
    "            if not np.all(np.isfinite(y_pred_val)): continue\n",
    "            mse = mean_squared_error(y_val, y_pred_val)\n",
    "            if not np.isnan(mse) and mse < best_mse:\n",
    "                 best_mse = mse; optim_found_params = params # Store only the tuned params\n",
    "        except Exception as e:\n",
    "            # print(f\"    FEIL GLM_H tuning params {params}: {e}\") # Optional debug\n",
    "            continue\n",
    "    if optim_found_params is None: print(\"    FEIL: GLM_H tuning mislyktes.\"); return None, np.array([]), np.array([]), {}\n",
    "    optimal_params = optim_found_params.copy()\n",
    "    try:\n",
    "        X_train_val = np.vstack((X_train, X_val)); y_train_val = np.concatenate((y_train, y_val))\n",
    "        # Combine base params with optimal tuned params for final fit\n",
    "        final_hub_params = {**base_hub_params, **optimal_params}\n",
    "        final_model = HuberRegressor(**final_hub_params).fit(X_train_val, y_train_val)\n",
    "        preds_oos = final_model.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
    "        preds_is = final_model.predict(X_train_val)\n",
    "        return final_model, preds_oos, preds_is, optimal_params\n",
    "    except Exception as e: print(f\"    FEIL GLM_H final: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "# Define _tune_tree_model helper\n",
    "def _tune_tree_model(ModelClass, X_train, y_train, X_val, y_val, model_params):\n",
    "    best_mse = np.inf; best_params = None; param_grid = list(ParameterGrid(model_params['param_grid']))\n",
    "    # Base parameters are those NOT in the grid (e.g., n_jobs, random_state, loss for GBRT)\n",
    "    base_params = {k: v for k, v in model_params.items() if k != 'param_grid'}\n",
    "    for params in param_grid:\n",
    "        try:\n",
    "            current_params = {**base_params, **params}\n",
    "            # Ensure max_features is valid if passed as float\n",
    "            if 'max_features' in current_params and isinstance(current_params['max_features'], float):\n",
    "                 current_params['max_features'] = max(1, int(current_params['max_features'] * X_train.shape[1]))\n",
    "\n",
    "            model_val = ModelClass(**current_params).fit(X_train, y_train)\n",
    "            y_pred_val = model_val.predict(X_val)\n",
    "            if not np.all(np.isfinite(y_pred_val)): continue\n",
    "            mse = mean_squared_error(y_val, y_pred_val)\n",
    "            if not np.isnan(mse) and mse < best_mse:\n",
    "                 best_mse = mse; best_params = params # Store only tuned params\n",
    "        except Exception as e:\n",
    "            # print(f\"    FEIL {ModelClass.__name__} tuning params {params}: {e}\") # Optional debug\n",
    "            continue\n",
    "    if best_params is None: print(f\"    FEIL: Tuning mislyktes for {ModelClass.__name__}.\")\n",
    "    return best_params\n",
    "\n",
    "# Define RF\n",
    "def train_evaluate_rf(X_train, y_train, X_val, y_val, X_test, model_params):\n",
    "    optimal_params = {}\n",
    "    try:\n",
    "        best_grid_params = _tune_tree_model(RandomForestRegressor, X_train, y_train, X_val, y_val, model_params)\n",
    "        if best_grid_params is None: raise ValueError(\"RF tuning failed.\")\n",
    "        optimal_params = best_grid_params.copy()\n",
    "        # Combine fixed params with optimal grid params\n",
    "        final_params = {**{k:v for k,v in model_params.items() if k!='param_grid'}, **optimal_params}\n",
    "        # Ensure max_features is valid if passed as float\n",
    "        if 'max_features' in final_params and isinstance(final_params['max_features'], float):\n",
    "             final_params['max_features'] = max(1, int(final_params['max_features'] * X_train.shape[1]))\n",
    "\n",
    "        X_train_val = np.vstack((X_train, X_val)); y_train_val = np.concatenate((y_train, y_val))\n",
    "        final_model = RandomForestRegressor(**final_params).fit(X_train_val, y_train_val)\n",
    "        preds_oos = final_model.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
    "        preds_is = final_model.predict(X_train_val)\n",
    "        return final_model, preds_oos, preds_is, optimal_params\n",
    "    except Exception as e: print(f\"    FEIL RF: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "# Define GBRT_H\n",
    "def train_evaluate_gbrt_h(X_train, y_train, X_val, y_val, X_test, model_params):\n",
    "    optimal_params = {}\n",
    "    try:\n",
    "        # Ensure 'loss' is set correctly from config, not overridden by grid search\n",
    "        gbrt_params = model_params.copy()\n",
    "        gbrt_params['loss'] = config.MODEL_PARAMS['GBRT_H'].get('loss', 'huber') # Explicitly set loss\n",
    "        best_grid_params = _tune_tree_model(GradientBoostingRegressor, X_train, y_train, X_val, y_val, gbrt_params)\n",
    "        if best_grid_params is None: raise ValueError(\"GBRT tuning failed.\")\n",
    "        optimal_params = best_grid_params.copy()\n",
    "        # Combine fixed params with optimal grid params\n",
    "        final_params = {**{k:v for k,v in gbrt_params.items() if k!='param_grid'}, **optimal_params}\n",
    "\n",
    "        X_train_val = np.vstack((X_train, X_val)); y_train_val = np.concatenate((y_train, y_val))\n",
    "        final_model = GradientBoostingRegressor(**final_params).fit(X_train_val, y_train_val)\n",
    "        preds_oos = final_model.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
    "        preds_is = final_model.predict(X_train_val)\n",
    "        # Return only the tuned grid params as optimal\n",
    "        return final_model, preds_oos, preds_is, optimal_params\n",
    "    except Exception as e: print(f\"    FEIL GBRT: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "# --- Define NN functions (if TF available) ---\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    def build_nn_model(input_shape, nn_config, lambda1):\n",
    "        model = keras.Sequential(name=nn_config['name'])\n",
    "        model.add(layers.Input(shape=(input_shape,)))\n",
    "        # Add Batch Normalization before the first hidden layer's activation\n",
    "        model.add(layers.BatchNormalization())\n",
    "        for units in nn_config['hidden_units']:\n",
    "            model.add(layers.Dense(units, kernel_regularizer=regularizers.l1(lambda1)))\n",
    "            # Add Batch Normalization after Dense layer, before activation\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Activation('relu')) # Use ReLU activation\n",
    "        model.add(layers.Dense(1, activation='linear')) # Linear output layer\n",
    "        return model\n",
    "\n",
    "    # Generic NN training function\n",
    "    def train_evaluate_nn(X_train, y_train, X_val, y_val, X_test, nn_shared_params, nn_specific_config):\n",
    "        model_name = nn_specific_config['name']; optimal_params = {}; best_val_mse = np.inf; optim_found_params = None\n",
    "        input_shape = X_train.shape[1]\n",
    "        param_grid = list(ParameterGrid(nn_shared_params['param_grid']))\n",
    "        epochs = nn_shared_params['epochs']; batch_size = nn_shared_params['batch_size']\n",
    "        patience = nn_shared_params['patience']; ensemble_size = nn_shared_params['ensemble_size']\n",
    "        base_seed = nn_shared_params['random_seed_base']\n",
    "\n",
    "        print(f\"      Tuning {model_name} ({len(param_grid)} combos)...\")\n",
    "        # Tuning Loop\n",
    "        for params in param_grid:\n",
    "            lambda1 = params['lambda1']; learning_rate = params['learning_rate']; val_preds_ensemble = []\n",
    "            current_val_mses = [] # Track MSE for each member in ensemble for this param set\n",
    "            try:\n",
    "                for i in range(ensemble_size):\n",
    "                    K.clear_session();\n",
    "                    member_seed = base_seed + i + random.randint(0, 10000) # Add more randomness\n",
    "                    tf.random.set_seed(member_seed); np.random.seed(member_seed); random.seed(member_seed)\n",
    "\n",
    "                    nn_model = build_nn_model(input_shape, nn_specific_config, lambda1)\n",
    "                    nn_model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse') # Mean Squared Error loss\n",
    "                    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True, verbose=0, mode='min')\n",
    "                    history = nn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, callbacks.TerminateOnNaN()], verbose=0)\n",
    "\n",
    "                    # Check if training was successful and val_loss exists\n",
    "                    if 'val_loss' in history.history and history.history['val_loss']:\n",
    "                         best_epoch_val_loss = min(history.history['val_loss'])\n",
    "                         if not np.isnan(best_epoch_val_loss):\n",
    "                              current_val_mses.append(best_epoch_val_loss)\n",
    "                              # Get predictions from the best weights restored by EarlyStopping\n",
    "                              val_preds_member = nn_model.predict(X_val, batch_size=batch_size, verbose=0).flatten()\n",
    "                              if np.all(np.isfinite(val_preds_member)):\n",
    "                                   val_preds_ensemble.append(val_preds_member)\n",
    "                              else:\n",
    "                                   # print(f\"      Warn: Non-finite val preds in ensemble member {i+1} for params {params}\");\n",
    "                                   val_preds_ensemble = []; break # Discard whole ensemble if one fails\n",
    "                         else:\n",
    "                             # print(f\"      Warn: NaN val_loss in ensemble member {i+1} for params {params}\")\n",
    "                             val_preds_ensemble = []; break\n",
    "                    else:\n",
    "                         # print(f\"      Warn: Training stopped early or val_loss missing for params {params}\")\n",
    "                         val_preds_ensemble = []; break\n",
    "\n",
    "                if not val_preds_ensemble: continue # Skip if ensemble failed\n",
    "\n",
    "                # Evaluate based on average prediction MSE or average member MSE\n",
    "                # Using average prediction MSE:\n",
    "                avg_val_preds = np.mean(np.array(val_preds_ensemble), axis=0)\n",
    "                finite_mask = np.isfinite(avg_val_preds) & np.isfinite(y_val)\n",
    "                if np.sum(finite_mask) > 0:\n",
    "                     val_mse = mean_squared_error(y_val[finite_mask], avg_val_preds[finite_mask])\n",
    "                     if not np.isnan(val_mse) and val_mse < best_val_mse:\n",
    "                          best_val_mse = val_mse; optim_found_params = params\n",
    "                          # print(f\"      New best params for {model_name}: {params} (MSE: {val_mse:.6f})\")\n",
    "                # else: print(f\"      Warn: No finite overlapping preds/targets for params {params}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    FEIL NN tuning {model_name} params {params}: {e}\"); traceback.print_exc(limit=1); continue\n",
    "\n",
    "        # Check Tuning Success\n",
    "        if optim_found_params is None: print(f\"    FEIL: NN tuning mislyktes for {model_name}.\"); return None, np.array([]), np.array([]), {}\n",
    "\n",
    "        optimal_params = optim_found_params.copy(); opt_lambda1 = optimal_params['lambda1']; opt_lr = optimal_params['learning_rate']\n",
    "        print(f\"      Optimal params for {model_name}: {optimal_params}\")\n",
    "\n",
    "        # Final Ensemble Training on Train + Val\n",
    "        final_model = None; test_preds_ensemble = []; is_preds_ensemble = []\n",
    "        try:\n",
    "            X_train_val = np.vstack((X_train, X_val)); y_train_val = np.concatenate((y_train, y_val))\n",
    "            print(f\"      Training final {model_name} ensemble ({ensemble_size} members)...\")\n",
    "            for i in range(ensemble_size):\n",
    "                K.clear_session();\n",
    "                final_seed = base_seed + i + ensemble_size + random.randint(0, 10000) # Different seeds for final run\n",
    "                tf.random.set_seed(final_seed); np.random.seed(final_seed); random.seed(final_seed)\n",
    "\n",
    "                nn_model_final = build_nn_model(input_shape, nn_specific_config, opt_lambda1)\n",
    "                nn_model_final.compile(optimizer=Adam(learning_rate=opt_lr), loss='mse')\n",
    "                # No early stopping for final model, train for full epochs\n",
    "                history_final = nn_model_final.fit(X_train_val, y_train_val, epochs=epochs, batch_size=batch_size, callbacks=[callbacks.TerminateOnNaN()], verbose=0)\n",
    "\n",
    "                if 'loss' not in history_final.history or not history_final.history['loss'] or np.isnan(history_final.history['loss']).any():\n",
    "                     print(f\"      FEIL: NaN loss during final training member {i+1} for {model_name}\")\n",
    "                     test_preds_ensemble = []; is_preds_ensemble = []; break # Discard ensemble\n",
    "\n",
    "                # Store IS and OOS predictions for this member\n",
    "                preds_i = nn_model_final.predict(X_train_val, batch_size=batch_size, verbose=0).flatten()\n",
    "                if np.all(np.isfinite(preds_i)): is_preds_ensemble.append(preds_i)\n",
    "                else: print(f\"      FEIL: Non-finite IS preds final member {i+1} for {model_name}\"); is_preds_ensemble = []; break\n",
    "\n",
    "                if X_test.shape[0] > 0:\n",
    "                    preds_t = nn_model_final.predict(X_test, batch_size=batch_size, verbose=0).flatten()\n",
    "                    if np.all(np.isfinite(preds_t)): test_preds_ensemble.append(preds_t)\n",
    "                    else: print(f\"      FEIL: Non-finite OOS preds final member {i+1} for {model_name}\"); test_preds_ensemble = []; break\n",
    "\n",
    "                # Keep the last trained model instance (for potential inspection, although ensemble average is used)\n",
    "                if i == ensemble_size - 1: final_model = nn_model_final\n",
    "\n",
    "            # Aggregate Predictions if ensemble finished successfully\n",
    "            if (X_test.shape[0] > 0 and len(test_preds_ensemble) != ensemble_size) or len(is_preds_ensemble) != ensemble_size:\n",
    "                 print(f\"    FEIL: {model_name} final ensemble failed or did not complete.\")\n",
    "                 return None, np.array([]), np.array([]), {}\n",
    "\n",
    "            preds_oos_final = np.mean(np.array(test_preds_ensemble), axis=0) if X_test.shape[0] > 0 else np.array([])\n",
    "            preds_is_final = np.mean(np.array(is_preds_ensemble), axis=0)\n",
    "            return final_model, preds_oos_final, preds_is_final, optimal_params\n",
    "        except Exception as e:\n",
    "            print(f\"    FEIL NN final training/prediction for {model_name}: {e}\"); traceback.print_exc(limit=1); return None, np.array([]), np.array([]), {}\n",
    "else:\n",
    "     print(\"TensorFlow ikke tilgjengelig, hopper over NN modeller.\")\n",
    "     # Define dummy functions if TF not available? Or rely on the check in main loop.\n",
    "# ==========================================================================\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "# --- MAIN EXECUTION SCRIPT ---\n",
    "# ==========================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    overall_start_time = datetime.datetime.now()\n",
    "    print(f\"--- Starter ML Asset Pricing Pipeline ---\")\n",
    "    print(f\"--- Starttidspunkt: {overall_start_time:%Y-%m-%d %H:%M:%S} ---\")\n",
    "    print(f\"--- Output lagres i: {config.OUTPUT_DIR} ---\")\n",
    "\n",
    "    # === 1: Load Preprocessed Data ===\n",
    "    df_loaded = utils.load_prepare_data(\n",
    "        config.DATA_FILE, config.COLUMN_CONFIG,\n",
    "        config.TARGET_VARIABLE, config.NEXT_RETURN_VARIABLE, config.MARKET_CAP_ORIG_VARIABLE\n",
    "    )\n",
    "    if df_loaded is None: exit(\"Avslutter: Lasting av forhåndsbehandlet data feilet.\")\n",
    "\n",
    "    # === 2: Define Features (from preprocessed data) ===\n",
    "    # *** Updated Exclusion List ***\n",
    "    base_exclude_list = [\n",
    "        config.TARGET_VARIABLE, config.NEXT_RETURN_VARIABLE, config.MARKET_CAP_ORIG_VARIABLE,\n",
    "        'Instrument', 'Date', 'id', 'date', # Include potential original names\n",
    "        'AdjustedReturn_t', 'MonthlyRiskFreeRate_t', # Exclude intermediate calcs if present\n",
    "        # *** Explicitly exclude user requested columns and variants ***\n",
    "        'MonthlyReturn_t', 'OpenPrice', 'monthlyreturn_t', 'openprice',\n",
    "        'MonthlyReturn', 'monthlyreturn', # Add base names too\n",
    "    ]\n",
    "    # Add specific raw names to exclude if their log versions are intended features (dynamic check)\n",
    "    # Check preprocess_data.py output for final log names (e.g., log_marketcap vs log_MarketCap)\n",
    "    if utils.find_col(df_loaded, ['log_MarketCap', 'log_marketcap']): base_exclude_list.extend(utils.find_col(df_loaded, [n]) for n in ['MarketCap', 'CommonSharesOutstanding', 'ClosePrice'] if utils.find_col(df_loaded, [n]))\n",
    "    if utils.find_col(df_loaded, ['log_BM', 'log_bm']): base_exclude_list.append(utils.find_col(df_loaded, ['BM', 'bm']))\n",
    "    # if utils.find_col(df_loaded, ['log_ClosePrice', 'log_closeprice']): base_exclude_list.append(utils.find_col(df_loaded, ['ClosePrice', 'closeprice'])) # Already excluded if MarketCap logged\n",
    "    if utils.find_col(df_loaded, ['log_Volume', 'log_volume']): base_exclude_list.append(utils.find_col(df_loaded, ['Volume', 'volume']))\n",
    "    # if utils.find_col(df_loaded, ['log_CommonSharesOutstanding', 'log_commonsharesoutstanding']): base_exclude_list.append(utils.find_col(df_loaded, ['CommonSharesOutstanding', 'commonsharesoutstanding'])) # Already excluded if MarketCap logged\n",
    "    if utils.find_col(df_loaded, ['TermSpread', 'termspread']): base_exclude_list.extend(utils.find_col(df_loaded, [n]) for n in ['NorgesBank10Y','NIBOR3M'] if utils.find_col(df_loaded, [n]))\n",
    "\n",
    "    # Remove None values potentially added by find_col if column wasn't found\n",
    "    base_exclude_list = sorted(list(set([col for col in base_exclude_list if col is not None])))\n",
    "    print(f\"INFO: Base columns to exclude from features: {base_exclude_list}\")\n",
    "\n",
    "    all_numeric_features_init, ols3_subset_features_init, _ = utils.define_features(\n",
    "        df_loaded, config.OLS3_FEATURE_NAMES, base_exclude_list\n",
    "    )\n",
    "    if not all_numeric_features_init: exit(\"Avslutter: Ingen features definert etter lasting.\")\n",
    "\n",
    "    # === 3: Rank Standardize Features ===\n",
    "    df_std = utils.rank_standardize_features(df_loaded, all_numeric_features_init)\n",
    "    if df_std is None: exit(\"Avslutter: Standardisering feilet.\")\n",
    "\n",
    "    # === 4: Clean Data (Post-Standardization) ===\n",
    "    df_clean = utils.clean_data(\n",
    "        df_std,\n",
    "        all_numeric_features_init, # Features to check for NaN/inf\n",
    "        config.ESSENTIAL_COLS_FOR_DROPNA, # Columns where NaN forces row drop\n",
    "        config.MARKET_CAP_ORIG_VARIABLE   # Column to check for > 0\n",
    "    )\n",
    "    if df_clean is None or df_clean.empty: exit(\"Avslutter: Dataframe tom etter rensing.\")\n",
    "\n",
    "    # === Final Feature Definition and Model Assignment ===\n",
    "    all_numeric_features, ols3_subset_features, _ = utils.define_features(\n",
    "        df_clean, config.OLS3_FEATURE_NAMES, base_exclude_list # Use same exclusion list\n",
    "    )\n",
    "    if not all_numeric_features: exit(\"FEIL: Ingen numeriske features igjen etter rensing.\")\n",
    "\n",
    "    ols3_required_count = len(config.OLS3_FEATURE_NAMES)\n",
    "    if not ols3_subset_features or len(ols3_subset_features) < ols3_required_count:\n",
    "        if config.RUN_MODELS.get('OLS3H', False): print(f\"\\nADVARSEL: Ikke alle {ols3_required_count} OLS3 features funnet ({ols3_subset_features}). OLS3H deaktiveres.\")\n",
    "        config.RUN_MODELS['OLS3H'] = False\n",
    "    elif config.RUN_MODELS.get('OLS3H', False): print(f\"\\nINFO: Alle OLS3 features funnet ({ols3_subset_features}). OLS3H er aktiv.\")\n",
    "\n",
    "    feature_map = {}\n",
    "    for model, fset_key in config.MODEL_FEATURE_MAP.items():\n",
    "        if fset_key == 'ols3_features': feature_map[model] = ols3_subset_features if config.RUN_MODELS.get('OLS3H', False) else []\n",
    "        elif fset_key == 'all_numeric': feature_map[model] = all_numeric_features\n",
    "        else: print(f\"Advarsel: Ukjent feature set key '{fset_key}' for {model}.\"); feature_map[model] = all_numeric_features\n",
    "\n",
    "    # === Initialize Results Storage ===\n",
    "    all_metrics = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    all_vi = defaultdict(lambda: defaultdict(list)); all_vi_avg = defaultdict(dict)\n",
    "    all_portfolios = defaultdict(dict); all_summaries = {}\n",
    "\n",
    "    # --- Define Actual Column Names (using config now) ---\n",
    "    target_col_actual_name = config.TARGET_VARIABLE\n",
    "    next_ret_col_actual_name = config.NEXT_RETURN_VARIABLE\n",
    "    mcap_orig_col_actual_name = config.MARKET_CAP_ORIG_VARIABLE\n",
    "    date_col_actual_name = 'Date'; id_col_actual_name = 'Instrument'\n",
    "\n",
    "    essential_check_list = [date_col_actual_name, id_col_actual_name, target_col_actual_name, next_ret_col_actual_name, mcap_orig_col_actual_name]\n",
    "    missing_essentials = [c for c in essential_check_list if c not in df_clean.columns]\n",
    "    if missing_essentials: exit(f\"FEIL: Nødvendige kolonner mangler i df_clean: {missing_essentials}.\")\n",
    "\n",
    "    # === 5: Outer Loop: Subsets ===\n",
    "    print(f\"\\n--- Starter Subset Loop: {config.SUBSETS_TO_RUN} ---\")\n",
    "    for subset in config.SUBSETS_TO_RUN:\n",
    "        subset_start_time = datetime.datetime.now()\n",
    "        print(f\"\\n{'='*30} Starter Subset: {subset.upper()} {'='*30}\")\n",
    "\n",
    "        # --- Create Subset Data ---\n",
    "        df_subset = pd.DataFrame()\n",
    "        df_mc_temp = df_clean.dropna(subset=[date_col_actual_name, mcap_orig_col_actual_name]).copy()\n",
    "        if df_mc_temp.empty: print(f\"FEIL: Ingen data for subsetting i {subset}.\"); continue\n",
    "        if subset == 'all': df_subset = df_clean.copy(); print(\"  Bruker fullt datasett.\")\n",
    "        else:\n",
    "            print(f\"  Definerer subset basert på {mcap_orig_col_actual_name} persentiler...\")\n",
    "            df_mc_temp['MonthYear'] = pd.to_datetime(df_mc_temp[date_col_actual_name]).dt.to_period('M')\n",
    "            if subset == 'big':\n",
    "                cutoff_quantile = 1.0 - (config.BIG_FIRM_TOP_PERCENT / 100.0)\n",
    "                size_cutoffs = df_mc_temp.groupby('MonthYear')[mcap_orig_col_actual_name].quantile(cutoff_quantile)\n",
    "                print(f\"  -> Topp {config.BIG_FIRM_TOP_PERCENT}% (Quantile: {cutoff_quantile:.2f})\")\n",
    "                df_mc_temp = df_mc_temp.join(size_cutoffs.rename('cutoff'), on='MonthYear')\n",
    "                # Handle cases where cutoff might be NaN (e.g., only one stock in a month)\n",
    "                df_subset = df_mc_temp[(df_mc_temp[mcap_orig_col_actual_name] >= df_mc_temp['cutoff']) | df_mc_temp['cutoff'].isna()].copy()\n",
    "            elif subset == 'small':\n",
    "                cutoff_quantile = config.SMALL_FIRM_BOTTOM_PERCENT / 100.0\n",
    "                size_cutoffs = df_mc_temp.groupby('MonthYear')[mcap_orig_col_actual_name].quantile(cutoff_quantile)\n",
    "                print(f\"  -> Bunn {config.SMALL_FIRM_BOTTOM_PERCENT}% (Quantile: {cutoff_quantile:.2f})\")\n",
    "                df_mc_temp = df_mc_temp.join(size_cutoffs.rename('cutoff'), on='MonthYear')\n",
    "                # Handle cases where cutoff might be NaN\n",
    "                df_subset = df_mc_temp[(df_mc_temp[mcap_orig_col_actual_name] <= df_mc_temp['cutoff']) | df_mc_temp['cutoff'].isna()].copy()\n",
    "\n",
    "            else: print(f\"FEIL: Ukjent subset '{subset}'.\"); continue\n",
    "            df_subset = df_subset.drop(columns=['MonthYear', 'cutoff'], errors='ignore')\n",
    "        if df_subset.empty: print(f\"FEIL: Subset '{subset}' er tomt.\"); continue\n",
    "        df_subset = df_subset.sort_values(by=[date_col_actual_name, id_col_actual_name]).reset_index(drop=True)\n",
    "        print(f\"  Subset '{subset}' klar. Form: {df_subset.shape}\")\n",
    "\n",
    "        # === 6: Inner Loop: Rolling Windows ===\n",
    "        try: splits = list(utils.get_yearly_rolling_splits(df_subset, config.INITIAL_TRAIN_YEARS, config.VALIDATION_YEARS, config.TEST_YEARS_PER_WINDOW))\n",
    "        except ValueError as e: print(f\"FEIL split gen for '{subset}': {e}\"); continue\n",
    "        except Exception as e_gen: print(f\"Uventet FEIL split gen for '{subset}': {e_gen}\"); traceback.print_exc(); continue\n",
    "        if not splits: print(f\"Ingen vinduer for '{subset}'.\"); continue\n",
    "        num_windows = len(splits)\n",
    "        print(f\"\\n--- Starter Rullerende Vindu Loop for Subset: {subset} ({num_windows} vinduer) ---\")\n",
    "        window_preds_list = []; last_train_idx, last_val_idx = None, None; last_models_fit = {}\n",
    "\n",
    "        for window_idx, (train_idx, val_idx, test_idx, train_dates, val_dates, test_dates) in enumerate(splits):\n",
    "            window_num = window_idx + 1; window_start_time = time.time()\n",
    "            print(f\"\\n-- Vindu {window_num}/{num_windows} ({subset}) --\")\n",
    "            if train_dates is not None: print(f\"  Train: {train_dates['min'].date()} -> {train_dates['max'].date()} ({len(train_idx)} obs)\")\n",
    "            else: print(\"  Train: Tomt\"); continue # Skip if no training data\n",
    "            if val_dates is not None:   print(f\"  Val:   {val_dates['min'].date()} -> {val_dates['max'].date()} ({len(val_idx)} obs)\")\n",
    "            else: print(\"  Val: Tomt\") # Val might be empty for some models\n",
    "            if test_dates is not None:  print(f\"  Test:  {test_dates['min'].date()} -> {test_dates['max'].date()} ({len(test_idx)} obs)\")\n",
    "            else: print(\"  Test: Tomt\"); continue # Skip if no test data\n",
    "\n",
    "            if test_idx.empty or train_idx.empty: print(\"  Advarsel: Tomt train/test sett.\"); continue\n",
    "            needs_val_set = lambda name: name not in ['OLS', 'OLS3H', 'ENET'] # Models needing validation set\n",
    "            if val_idx.empty and any(config.RUN_MODELS[m] and needs_val_set(m) for m in config.RUN_MODELS if config.RUN_MODELS[m]):\n",
    "                 print(\"  ADVARSEL: Tomt val set, men trengs av noen modeller. Hopper over disse modellene.\");\n",
    "\n",
    "            # Prepare data for this window\n",
    "            y_train = df_subset.loc[train_idx, target_col_actual_name].values\n",
    "            y_val = df_subset.loc[val_idx, target_col_actual_name].values if not val_idx.empty else np.array([])\n",
    "            y_test = df_subset.loc[test_idx, target_col_actual_name].values\n",
    "            y_train_val = np.concatenate((y_train, y_val)) if not val_idx.empty else y_train\n",
    "\n",
    "            # Ensure targets are finite\n",
    "            y_train_finite_mask = np.isfinite(y_train)\n",
    "            y_train = y_train[y_train_finite_mask]\n",
    "            train_idx = train_idx[y_train_finite_mask]\n",
    "            if not val_idx.empty:\n",
    "                y_val_finite_mask = np.isfinite(y_val)\n",
    "                y_val = y_val[y_val_finite_mask]\n",
    "                val_idx = val_idx[y_val_finite_mask]\n",
    "            y_train_val = np.concatenate((y_train, y_val)) if not val_idx.empty else y_train\n",
    "\n",
    "\n",
    "            window_results = {date_col_actual_name: df_subset.loc[test_idx, date_col_actual_name].values, id_col_actual_name: df_subset.loc[test_idx, id_col_actual_name].values, target_col_actual_name: y_test}\n",
    "            nan_preds = np.full(len(test_idx), np.nan)\n",
    "            for model_name_init, run_flag in config.RUN_MODELS.items():\n",
    "                if run_flag: window_results[f'yhat_{model_name_init.lower()}'] = nan_preds.copy()\n",
    "            window_models_fitted_this_run = {}\n",
    "\n",
    "            # === 7: Innermost Loop: Models ===\n",
    "            for model_name, do_run in config.RUN_MODELS.items():\n",
    "                if not do_run: continue\n",
    "                if model_name == 'OLS3H' and (not STATSMODELS_AVAILABLE or not config.RUN_MODELS['OLS3H']): continue\n",
    "                if model_name.startswith('NN') and not TENSORFLOW_AVAILABLE: continue\n",
    "\n",
    "                print(f\"  -> Trener/Evaluerer: {model_name}...\")\n",
    "                model_start_time = time.time(); fitted_model, preds_oos, preds_is, optimal_hyperparams = None, np.array([]), np.array([]), {}; y_is_target = np.array([])\n",
    "\n",
    "                current_features = feature_map.get(model_name);\n",
    "                current_features = [f for f in current_features if f in df_subset.columns] # Ensure features exist\n",
    "                if not current_features: print(f\"    Advarsel: Ingen features for {model_name} i dette vinduet/subset.\"); continue\n",
    "\n",
    "                # Get data using the potentially filtered indices\n",
    "                X_train = df_subset.loc[train_idx, current_features].values\n",
    "                X_val = df_subset.loc[val_idx, current_features].values if not val_idx.empty else np.empty((0, len(current_features)))\n",
    "                X_test = df_subset.loc[test_idx, current_features].values\n",
    "                X_train_val = np.vstack((X_train, X_val)) if not val_idx.empty else X_train\n",
    "\n",
    "                # Check data validity again after potential filtering\n",
    "                min_obs_train = max(2, X_train.shape[1] + 1) if model_name == 'OLS3H' else 2\n",
    "                if X_train.shape[0] < min_obs_train or len(y_train)==0: print(f\"    Advarsel: Utilstrekkelig train data ({X_train.shape[0]} obs).\"); continue\n",
    "                if val_idx.empty and needs_val_set(model_name): print(f\"    Advarsel: Tomt val set, kan ikke trene {model_name}.\"); continue\n",
    "                if not val_idx.empty and (X_val.shape[0] < 2 or len(y_val)==0) and needs_val_set(model_name): print(f\"    Advarsel: Utilstrekkelig val data ({X_val.shape[0]} obs).\"); continue\n",
    "\n",
    "                try:\n",
    "                    # *** Corrected NN Function Call Logic ***\n",
    "                    if model_name.startswith('NN'):\n",
    "                        if TENSORFLOW_AVAILABLE:\n",
    "                            train_function = train_evaluate_nn # Use the generic NN trainer\n",
    "                            nn_specific_config = config.MODEL_PARAMS.get(model_name, {})\n",
    "                            if not nn_specific_config: print(f\"    FEIL: Mangler config for {model_name}\"); continue\n",
    "                            fitted_model, preds_oos, preds_is, optimal_hyperparams = train_function(\n",
    "                                X_train, y_train, X_val, y_val, X_test,\n",
    "                                config.MODEL_PARAMS['NN_SHARED'], # Pass shared NN params\n",
    "                                nn_specific_config                 # Pass specific NN config (layers etc)\n",
    "                            )\n",
    "                            y_is_target = y_train_val # NNs train on train+val after tuning\n",
    "                        else:\n",
    "                            continue # Skip NN if TF not available\n",
    "                    else:\n",
    "                        # Call specific function for other models\n",
    "                        train_func_name = f\"train_evaluate_{model_name.lower().replace('-', '').replace('+', '_')}\"\n",
    "                        train_function = locals().get(train_func_name)\n",
    "                        if train_function:\n",
    "                            model_config_params = config.MODEL_PARAMS.get(model_name, {})\n",
    "                            if model_name in ['OLS', 'OLS3H']: fitted_model, preds_oos, preds_is, optimal_hyperparams = train_function(X_train_val, y_train_val, X_test, model_config_params); y_is_target = y_train_val\n",
    "                            elif model_name == 'ENET': fitted_model, preds_oos, preds_is, optimal_hyperparams = train_function(X_train, y_train, X_test, model_config_params); y_is_target = y_train # ENET CV on train only\n",
    "                            else: fitted_model, preds_oos, preds_is, optimal_hyperparams = train_function(X_train, y_train, X_val, y_val, X_test, model_config_params); y_is_target = y_train_val\n",
    "                        else: print(f\"    FEIL: Treningsfunksjon '{train_func_name}' ikke funnet.\"); continue\n",
    "\n",
    "                    # Process results if training was successful\n",
    "                    if preds_oos is not None and preds_is is not None and len(preds_oos) == len(y_test):\n",
    "                        # Ensure predictions are finite before calculating metrics\n",
    "                        finite_oos_mask = np.isfinite(preds_oos)\n",
    "                        finite_is_mask = np.isfinite(preds_is)\n",
    "\n",
    "                        preds_oos_finite=preds_oos[finite_oos_mask]; y_test_aligned_oos=y_test[finite_oos_mask]\n",
    "                        preds_is_finite=preds_is[finite_is_mask]; y_is_target_aligned_is=y_is_target[finite_is_mask]\n",
    "\n",
    "                        r2_oos=utils.calculate_oos_r2(y_test_aligned_oos, preds_oos_finite) if len(y_test_aligned_oos)>=2 else np.nan\n",
    "                        r2_is=utils.calculate_oos_r2(y_is_target_aligned_is, preds_is_finite) if len(y_is_target_aligned_is)>=2 else np.nan\n",
    "                        sharpe_oos=utils.calculate_sharpe_of_predictions(preds_oos_finite) if len(preds_oos_finite)>=2 else np.nan\n",
    "\n",
    "                        all_metrics[subset][model_name]['oos_r2'].append(r2_oos)\n",
    "                        all_metrics[subset][model_name]['is_r2_train_val'].append(r2_is)\n",
    "                        all_metrics[subset][model_name]['oos_sharpe'].append(sharpe_oos)\n",
    "                        for param_name, param_value in optimal_hyperparams.items(): all_metrics[subset][model_name][f'optim_{param_name}'].append(param_value)\n",
    "\n",
    "                        pred_col_name=f'yhat_{model_name.lower()}'\n",
    "                        # Place predictions into results, handling NaNs where needed\n",
    "                        window_results[pred_col_name].fill(np.nan) # Reset column first\n",
    "                        if len(preds_oos) == len(window_results[pred_col_name]):\n",
    "                             window_results[pred_col_name][:] = preds_oos # Assign valid predictions\n",
    "                        else:\n",
    "                              print(f\"    Advarsel: Lengde mismatch for {model_name} prediksjoner.\")\n",
    "\n",
    "                        if fitted_model is not None: window_models_fitted_this_run[model_name] = fitted_model\n",
    "                        print(f\"    {model_name}: OOS R²={r2_oos:.4f}, IS R²={r2_is:.4f}, Sharpe={sharpe_oos:.3f} ({time.time()-model_start_time:.1f}s)\")\n",
    "\n",
    "                        # --- Calculate VI (if requested and strategy matches) ---\n",
    "                        if config.CALCULATE_VI and fitted_model is not None and config.MODEL_VI_STRATEGY.get(model_name) == 'per_window':\n",
    "                            if pd.notna(r2_is):\n",
    "                                vi_start_time = time.time()\n",
    "                                # Determine data for VI based on where IS R2 was calculated\n",
    "                                if model_name == 'ENET':\n",
    "                                     X_eval_vi_data = X_train; y_eval_vi_data = y_train\n",
    "                                else:\n",
    "                                     X_eval_vi_data = X_train_val; y_eval_vi_data = y_is_target\n",
    "\n",
    "                                if X_eval_vi_data.shape[0] > 0 and y_eval_vi_data.shape[0] > 0:\n",
    "                                    # Pass optimal hyperparams found in this window\n",
    "                                    vi_df = utils.calculate_variable_importance(model_name, fitted_model, X_eval_vi_data, y_eval_vi_data, current_features, r2_is, config.VI_METHOD, optimal_hyperparams)\n",
    "                                    if vi_df is not None and not vi_df.empty: all_vi[subset][model_name].append(vi_df)\n",
    "                                else: print(f\"      Advarsel: Ingen data for VI for {model_name}.\")\n",
    "                            else: print(f\"    Advarsel: Hopper over VI for {model_name} pga. NaN IS R2.\")\n",
    "                    else:\n",
    "                        print(f\"    Advarsel: {model_name} returnerte ingen/feil prediksjoner.\");\n",
    "                        all_metrics[subset][model_name]['oos_r2'].append(np.nan); all_metrics[subset][model_name]['is_r2_train_val'].append(np.nan); all_metrics[subset][model_name]['oos_sharpe'].append(np.nan)\n",
    "\n",
    "                except Exception as e_train:\n",
    "                    print(f\"    !!! KRITISK FEIL under trening/evaluering av {model_name}: {e_train}\"); traceback.print_exc();\n",
    "                    all_metrics[subset][model_name]['oos_r2'].append(np.nan); all_metrics[subset][model_name]['is_r2_train_val'].append(np.nan); all_metrics[subset][model_name]['oos_sharpe'].append(np.nan)\n",
    "\n",
    "            # End Model Loop\n",
    "            window_preds_list.append(pd.DataFrame(window_results))\n",
    "            # Store indices and models from the *last successfully completed* window for last_window VI\n",
    "            if window_idx == num_windows - 1:\n",
    "                 last_train_idx=train_idx.copy()\n",
    "                 last_val_idx=val_idx.copy() if not val_idx.empty else None\n",
    "                 last_models_fit=window_models_fitted_this_run.copy()\n",
    "            print(f\"-- Vindu {window_num} ({subset}) fullført ({time.time() - window_start_time:.1f}s) --\")\n",
    "        # End Window Loop\n",
    "\n",
    "        # === 8-10: Post-Window Analysis for the Subset ===\n",
    "        if not window_preds_list: print(f\"\\nFEIL: Ingen vindusprediksjoner for '{subset}'.\"); continue\n",
    "        print(f\"\\n--- Analyserer resultater for Subset: {subset} ---\")\n",
    "        results_df_subset=pd.concat(window_preds_list).reset_index(drop=True)\n",
    "\n",
    "        # Identify prediction columns that actually contain non-NaN data\n",
    "        prediction_cols_subset = [c for c in results_df_subset.columns if c.startswith('yhat_') and results_df_subset[c].notna().any()]\n",
    "        if not prediction_cols_subset: print(f\"FEIL: Ingen gyldige prediksjonskolonner funnet i results_df for '{subset}'.\"); continue\n",
    "\n",
    "        # Calculate Overall OOS R2 (Gu Definition)\n",
    "        print(f\"\\n--- Overall OOS R² (Gu-stil) for Subset: {subset} ---\")\n",
    "        y_true_overall=results_df_subset[target_col_actual_name]\n",
    "        # Check if there are any finite true values\n",
    "        if not np.any(np.isfinite(y_true_overall)):\n",
    "             print(\"  Kan ikke beregne overall OOS R2: Ingen finite y_true verdier.\")\n",
    "        else:\n",
    "             y_true_finite_overall=y_true_overall[np.isfinite(y_true_overall)]\n",
    "             ss_tot_overall=np.sum(y_true_finite_overall**2)\n",
    "             if len(y_true_finite_overall) > 1 and ss_tot_overall > 1e-15:\n",
    "                 for pred_col in prediction_cols_subset:\n",
    "                     model_name_oos=pred_col.replace('yhat_', '').upper().replace('_', '-') # Clean model name\n",
    "                     y_pred_overall=results_df_subset[pred_col]\n",
    "                     mask_overall=np.isfinite(y_true_overall)&np.isfinite(y_pred_overall)\n",
    "                     y_t_o=y_true_overall[mask_overall]; y_p_o=y_pred_overall[mask_overall]\n",
    "                     if len(y_t_o) >= 2:\n",
    "                          r2_overall_gu=utils.calculate_oos_r2(y_t_o, y_p_o)\n",
    "                          all_metrics[subset][model_name_oos]['oos_r2_overall_gu']=r2_overall_gu\n",
    "                          print(f\"  {model_name_oos}: {r2_overall_gu:.6f}\")\n",
    "                     else:\n",
    "                          print(f\"  {model_name_oos}: N/A (for få overlappende finite verdier)\")\n",
    "                          all_metrics[subset][model_name_oos]['oos_r2_overall_gu']=np.nan\n",
    "             else: print(\"  Kan ikke beregne overall OOS R2 (for få observasjoner eller SS_tot nær null).\")\n",
    "\n",
    "        # Perform Portfolio Analysis (passing VALID prediction cols)\n",
    "        print(f\"\\n--- Starter Detaljert Porteføljeanalyse for Subset: {subset} ---\")\n",
    "        decile_tables, hl_risk_tables, long_risk_tables = utils.perform_detailed_portfolio_analysis(\n",
    "            results_df_subset, df_clean, prediction_cols_subset, # Pass only valid cols\n",
    "            mcap_orig_col_actual_name, next_ret_col_actual_name,\n",
    "            config.FILTER_SMALL_CAPS_PORTFOLIO, config.ANNUALIZATION_FACTOR,\n",
    "            config.BENCHMARK_FILE, config.FF_FACTOR_FILE\n",
    "            )\n",
    "        all_portfolios[subset]={'decile_tables': decile_tables, 'hl_risk_tables': hl_risk_tables, 'long_risk_tables': long_risk_tables}\n",
    "\n",
    "        # Calculate Average/Last Window Variable Importance\n",
    "        if config.CALCULATE_VI:\n",
    "            print(f\"\\n--- Beregner Variabel Viktighet (VI) for Subset: {subset} ---\")\n",
    "            for model_name, do_run in config.RUN_MODELS.items():\n",
    "                if not do_run: continue\n",
    "                # Skip models that consistently fail or aren't available\n",
    "                if model_name=='OLS3H' and (not STATSMODELS_AVAILABLE or not config.RUN_MODELS['OLS3H']): continue\n",
    "                if model_name.startswith('NN') and not TENSORFLOW_AVAILABLE: continue\n",
    "                # Skip if no metrics were calculated for this model (implies it never ran successfully)\n",
    "                if model_name not in all_metrics[subset]: print(f\"  Hopper over VI for {model_name} (ingen metrikker funnet).\"); continue\n",
    "\n",
    "                vi_strategy=config.MODEL_VI_STRATEGY.get(model_name);\n",
    "                current_features_vi=feature_map.get(model_name); current_features_vi=[f for f in current_features_vi if f in df_subset.columns]\n",
    "                if not current_features_vi: print(f\"  Hopper over VI for {model_name} (ingen features funnet).\"); continue\n",
    "\n",
    "                if vi_strategy=='per_window':\n",
    "                    vi_list_model = all_vi[subset].get(model_name, [])\n",
    "                    if vi_list_model:\n",
    "                        try:\n",
    "                            # Filter out empty DataFrames before concatenating\n",
    "                            valid_vi_dfs = [df for df in vi_list_model if isinstance(df, pd.DataFrame) and not df.empty]\n",
    "                            if valid_vi_dfs:\n",
    "                                avg_vi_df=pd.concat(valid_vi_dfs).groupby('Feature')['Importance'].mean().reset_index()\n",
    "                                total_avg_importance=avg_vi_df['Importance'].sum()\n",
    "                                avg_vi_df['Importance']=avg_vi_df['Importance']/total_avg_importance if total_avg_importance > 1e-9 else 0.0\n",
    "                                all_vi_avg[subset][model_name]=avg_vi_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "                                print(f\"  VI (Avg/Window) beregnet for {model_name}.\")\n",
    "                            else: print(f\"  Ingen gyldige 'per_window' VI dataFrames for {model_name}.\")\n",
    "                        except Exception as e_vi_avg: print(f\"  FEIL under VI avg for {model_name}: {e_vi_avg}\")\n",
    "                    else: print(f\"  Ingen 'per_window' VI data funnet for {model_name}.\")\n",
    "                elif vi_strategy=='last_window':\n",
    "                    print(f\"  Beregner 'last_window' VI for {model_name}...\")\n",
    "                    if last_train_idx is None or model_name not in last_models_fit: print(f\"    Hoppet over {model_name} (mangler data/modell fra siste vindu).\"); continue\n",
    "\n",
    "                    last_model_instance=last_models_fit[model_name]\n",
    "                    last_is_r2_list=all_metrics[subset][model_name].get('is_r2_train_val', [])\n",
    "                    last_is_r2 = last_is_r2_list[-1] if last_is_r2_list else np.nan\n",
    "\n",
    "                    if pd.isna(last_is_r2): print(f\"    Advarsel: IS R2 siste vindu NaN for {model_name}, hopper VI.\"); continue\n",
    "\n",
    "                    # Get optimal hyperparams from the last window\n",
    "                    last_optimal_params = {}\n",
    "                    for k, v_list in all_metrics[subset][model_name].items():\n",
    "                         if k.startswith('optim_') and v_list:\n",
    "                             last_optimal_params[k.replace('optim_', '')] = v_list[-1]\n",
    "\n",
    "                    # Determine data used for IS R2 calculation in the last window\n",
    "                    if model_name == 'ENET':\n",
    "                         X_eval_last=df_subset.loc[last_train_idx, current_features_vi].values\n",
    "                         y_eval_last=df_subset.loc[last_train_idx, target_col_actual_name].values\n",
    "                    else:\n",
    "                         last_full_idx=last_train_idx.union(last_val_idx) if last_val_idx is not None else last_train_idx\n",
    "                         X_eval_last=df_subset.loc[last_full_idx, current_features_vi].values\n",
    "                         y_eval_last=df_subset.loc[last_full_idx, target_col_actual_name].values\n",
    "\n",
    "                    # Ensure data is valid before calculating VI\n",
    "                    if X_eval_last.shape[0] > 0 and y_eval_last.shape[0] > 0:\n",
    "                         vi_df_last=utils.calculate_variable_importance(\n",
    "                             model_name, last_model_instance, X_eval_last, y_eval_last,\n",
    "                             current_features_vi, last_is_r2, config.VI_METHOD, last_optimal_params\n",
    "                         )\n",
    "                         if vi_df_last is not None and not vi_df_last.empty:\n",
    "                             all_vi_avg[subset][model_name]=vi_df_last.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "                             print(f\"    VI ({model_name}, siste vindu) beregnet.\")\n",
    "                         else: print(f\"    VI beregning siste vindu ({model_name}) mislyktes eller returnerte tom.\")\n",
    "                    else: print(f\"    Advarsel: Ingen gyldige evalueringsdata for VI siste vindu ({model_name}).\")\n",
    "\n",
    "        # Generate Summary Table, Plot Complexity, Plot VI\n",
    "        all_summaries[subset] = utils.create_summary_table(all_metrics[subset], config.ANNUALIZATION_FACTOR)\n",
    "        utils.plot_time_varying_complexity(all_metrics[subset], config.COMPLEXITY_PARAMS_TO_PLOT)\n",
    "        if config.CALCULATE_VI and all_vi_avg[subset]:\n",
    "             print(f\"\\n--- Plotter Variabel Viktighet for Subset: {subset} ---\")\n",
    "             for model_name, vi_df in all_vi_avg[subset].items():\n",
    "                 if vi_df is None or vi_df.empty: continue # Skip if no VI data\n",
    "                 plt.figure(figsize=(10, max(6, min(len(vi_df), config.VI_PLOT_TOP_N) * 0.3)))\n",
    "                 plot_df = vi_df[vi_df['Importance'] > 1e-6].head(config.VI_PLOT_TOP_N).sort_values(by='Importance', ascending=True)\n",
    "                 if not plot_df.empty:\n",
    "                      plt.barh(plot_df['Feature'], plot_df['Importance'])\n",
    "                      plt.xlabel(\"Relativ Viktighet (Permutation Importance)\")\n",
    "                      plt.title(f\"{model_name} Variable Importance ({subset} - Top {len(plot_df)})\")\n",
    "                      plt.tight_layout(); plt.show()\n",
    "                 else: print(f\"  Ingen VI data å plotte for {model_name} ({subset}).\"); plt.close()\n",
    "\n",
    "        # Save Results\n",
    "        results_to_save={\n",
    "            'summary_metrics': all_summaries[subset],\n",
    "            'portfolio_deciles': all_portfolios[subset].get('decile_tables', {}),\n",
    "            'portfolio_hl_risk': all_portfolios[subset].get('hl_risk_tables', {}),\n",
    "            'portfolio_long_risk': all_portfolios[subset].get('long_risk_tables', {}),\n",
    "            'variable_importance_avg': all_vi_avg[subset],\n",
    "            # Optionally save raw predictions if needed\n",
    "            # 'raw_predictions': results_df_subset\n",
    "            }\n",
    "        utils.save_results(config.OUTPUT_DIR, subset, results_to_save)\n",
    "        subset_end_time = datetime.datetime.now()\n",
    "        print(f\"\\n{'='*30} Subset Fullført: {subset.upper()} (Tid: {subset_end_time - subset_start_time}) {'='*30}\")\n",
    "    # End Subset Loop\n",
    "\n",
    "    # === Final Reporting ===\n",
    "    print(\"\\n\\n\" + \"=\"*35 + \" SLUTTSAMMENDRAG \" + \"=\"*35)\n",
    "    r2_final_data = defaultdict(dict)\n",
    "    for sub in config.SUBSETS_TO_RUN:\n",
    "        if sub in all_metrics:\n",
    "            for model, metrics in all_metrics[sub].items():\n",
    "                # Check if the model actually ran and produced an overall R2\n",
    "                if 'oos_r2_overall_gu' in metrics:\n",
    "                     r2_final_data[sub][model] = metrics['oos_r2_overall_gu'] * 100\n",
    "                else:\n",
    "                     r2_final_data[sub][model] = np.nan # Mark as NaN if not calculated\n",
    "    if r2_final_data:\n",
    "        r2_summary_final = pd.DataFrame.from_dict(r2_final_data, orient='index')\n",
    "        # Ensure all models from config.RUN_MODELS are columns, even if they didn't run\n",
    "        model_order_final = [m for m in config.RUN_MODELS if config.RUN_MODELS[m]] # Models intended to run\n",
    "        all_cols = model_order_final + sorted([m for m in r2_summary_final.columns if m not in model_order_final])\n",
    "        r2_summary_final = r2_summary_final.reindex(columns=all_cols, fill_value=np.nan)\n",
    "        r2_summary_final.index.name=\"Subset\"; r2_summary_final.columns.name=\"Model\"\n",
    "        print(\"\\n--- Tabell 1 Stil: Overall Monthly OOS R² (%) [Gu et al. Def] ---\")\n",
    "        print(r2_summary_final.to_string(float_format=lambda x: f\"{x:.3f}\" if pd.notna(x) else \"N/A\", na_rep=\"N/A\"))\n",
    "        utils.save_results(config.OUTPUT_DIR, \"consolidated\", {\"R2_summary_table1_style\": r2_summary_final})\n",
    "    else: print(\"\\nIngen data for endelig OOS R2-oppsummering.\")\n",
    "    overall_end_time = datetime.datetime.now()\n",
    "    print(f\"\\n--- Pipeline Fullført ---\"); print(f\"--- Sluttidspunkt: {overall_end_time:%Y-%m-%d %H:%M:%S} ---\"); print(f\"--- Total Kjøretid: {overall_end_time - overall_start_time} ---\"); print(f\"--- Resultater lagret i: {config.OUTPUT_DIR} ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
